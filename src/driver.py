import gevent
import zerorpc
from src.rdd.rdd import WideRDD, TextFile, GroupByKey, Map, Join
from src.task import Task
from src.util import util_pickle

class SparkDriver:
    def __init__(self, job):
        self.actions = {"reduce": self.do_reduce,
                        "collect": self.do_collect,
                        "count": self.do_count
                        }
        # task_list: {task: status}
        self.task_list = {}
        # task_node_table: {worker_id: [tasks]}
        self.task_node_table = {}
        self.master_addr = None
        self.func = None
        self.action = None
        self.result = []
        self.result_ready = gevent.event.Event()
        self.result_ready.clear()
        self.job = util_pickle.unpickle_object(job)

    def run(self):
        self.job.run()

    def do_drive(self, serialized_rdd, action_name, func):
        last_rdd = util_pickle.unpickle_object(serialized_rdd)
        self.action = self.actions[action_name]
        self.func = func
        self.master_addr = last_rdd._config['master_addr']
        lineage = last_rdd.get_lineage()

        # generate graph-table and stages
        # partition_graph = self.gen_graph_table(last_rdd)
        self.init_tasks(lineage)
        # Do some fuction to generate the rdd that apply the operation and the result
        for task in self.task_list.keys():
            gevent.spawn(self.assign_task, task)

        self.result_ready.wait()
        return self.action(self, func)

    def result_collected_notify(self, event):
        self.result_ready.set()

    def fault_handler(self, worker_id):
        for task in self.task_node_table[worker_id]:
            gevent.spawn(self.assign_task, task)
        self.task_node_table.__delitem__(worker_id)

    def assign_task(self, task):
        """Assign the stages list to Master Node,
           return the last rdd that action should be applied"""
        master = zerorpc.Client()
        master.connect("tcp://{0}".format(self.master_addr))
        worker_info = master.get_available_worker()
        while worker_info is None:
            gevent.sleep(1)
            worker_info = master.get_available_worker()
        if isinstance(task.input_source, list):
            task.input_source['worker_addr'] = worker_info['address']
        task.worker = worker_info
        if self.task_node_table.has_key(worker_info["woker_id"]):
            self.task_node_table[worker_info["woker_id"]].append(task)
        else:
            self.task_node_table[worker_info["woker_id"]] = [task]
        worker = zerorpc.Client()
        worker.connect("tcp://".format(worker_info['address']))
        worker.startTask(util_pickle.pickle_object(task))
        self.task_list[task] = "Assigned"

    def init_tasks(self, lineage):
        """
        Generate task list for works
        :param lineage: The lineage of RDDs
        """
        tasks = {}
        cur_stage_id = 0
        prev = lineage[0][0]
        stage_start = lineage[0][0]
        for rdd, rdd_id in lineage:
            if isinstance(rdd, WideRDD):
                tasks.update(self.gen_stage_tasks(prev, stage_start, cur_stage_id))
                cur_stage_id += 1
                stage_start = rdd
            prev = rdd

        # Handle the last stage
        self.last_tasks = self.gen_stage_tasks(prev, stage_start, cur_stage_id)
        tasks.update(self.last_tasks)
        self.task_list = tasks

    def gen_stage_tasks(self, start_rdd, last_rdd, cur_stage_id):
        """
        Generate a single task for a stage
        :param last_rdd: The last Rdd of stage
        :param start_rdd: The first Rdd of stage
        :param cur_stage_id: The ID of current stage
        :return: The list of tasks generated by the stage
        """
        tasks = {}
        graph_table = last_rdd.partitions()
        for cur_par_id in range(0, len(graph_table)):
            if isinstance(start_rdd, TextFile):
                # TextFile data source
                input_source = str(cur_par_id)
            elif isinstance(start_rdd, WideRDD):
                # Shuffle data source\
                input_source = []
                if not isinstance(start_rdd.parent, list):
                    parents = [start_rdd.parent]
                else:
                    parents = start_rdd.parent
                for parent_rdd in parents:
                    # parent_graph: [['0_0', '0_1'],['1_0','1_1']]
                    parent_graph = parent_rdd.partitions()
                    for tar_list in parent_graph:
                        for elem in tar_list:
                            if int(elem.split('_')[1]) == cur_par_id:
                                # elem_dict: {'parent_id': rdd.id, 'partition_id': str(id), worker_addr: 'XXXX:XX'}
                                elem_dict = {'task_id': "{0}_{1}".format(cur_stage_id, cur_par_id),
                                             'partition_id': elem.split('_')[0]}
                                input_source.append(elem_dict)
            else:
                input_source = None
            tasks.update({Task(last_rdd, input_source, "{0}_{1}".format(cur_stage_id, cur_par_id)): 'New'})
        return tasks

    def finish_task(self, task_id):
        for task in self.task_list.keys():
            if task.task_id == task_id:
                self.task_list[task] = "Finished"
                break
        for task in self.last_tasks.keys():
            if self.task_list[task] is not 'Finished':
                return
        collect_process = gevent.spawn(self.get_all_results)
        collect_process.link(self.result_collected_notify)

    def get_all_results(self):
        for i in range(0, len(self.last_tasks)):
            gevent.spawn(self.get_result, self.last_tasks.keys()[i], i)

    def get_result(self, task, task_index):
        worker = zerorpc.Client()
        worker.connect('tcp://{0}'.format(task.worker['address']))
        self.result += worker.get_rdd_result(task.task_id, task_index)

    def do_reduce(self, func):
        return reduce(func, self.do_collect())

    def do_collect(self, func=None):
        return self.result

    def do_count(self,func=None):
        return len(self.result)




